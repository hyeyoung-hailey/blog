
## **1.  ê°œìš”**
 ì´ ê¸€ì—ì„œëŠ” **Kafka, MySQL, Docker, Debezium**ì„ í™œìš©í•´ CDC(ë°ì´í„° ë³€ê²½ ì‚¬í•­ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì§€í•˜ê³  ë°˜ì˜í•˜ëŠ”)ë¥¼ êµ¬í˜„í•˜ê³ , **Java ê¸°ë°˜ Kafka Consumer**ë¥¼ í†µí•´ ë³€ê²½ëœ ë°ì´í„°ë¥¼ **Redisì— ì €ì¥í•˜ì—¬ Cache** ì²˜ë¦¬í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¹ë‹ˆë‹¤.

## **2.  CDCë€?**
- ë°ì´í„°ë² ì´ìŠ¤ ë³€ê²½ ì‚¬í•­ì„ ì´ë²¤íŠ¸ë¡œ ì¶”ì¶œí•˜ëŠ” ê¸°ìˆ 
- ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™”, ë°ì´í„° ë¶„ì„ ë“±ì— í™œìš©

## **3.  Debeziumê³¼ Kafka ì†Œê°œ**
- **Debezium**: ë°ì´í„°ë² ì´ìŠ¤ ë³€ê²½ ì‚¬í•­ì„ ê°ì§€í•˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ í”„ë ˆì„ì›Œí¬
- **Kafka**: ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°í•˜ëŠ” ë©”ì‹œì§€ ë¸Œë¡œì»¤

## **4.  í”„ë¡œì íŠ¸ ì„¤ì •

>[!NOTE]
>- Docker : Kafka, Zookeeper, Kafka Connect, MySQL, Debezium ì‹¤í–‰
>- Kafka & Zookeeper: ë©”ì‹œì§€ ë¸Œë¡œì»¤ ì—­í• 
>- Debezium: MySQLì˜ ë³€ê²½ ì‚¬í•­ì„ Kafkaë¡œ ì „ì†¡
>- Java ê¸°ë°˜ Kafka Consumer: CDC ì´ë²¤íŠ¸ ì²˜ë¦¬
### **1) biuld.gradle**
```groovy
//kafka  
implementation 'org.springframework.kafka:spring-kafka'
//Redis
implementation 'org.springframework.boot:spring-boot-starter-data-redis'
```
### **2) application.yml Kafka, Redis ì„¤ì • ì¶”ê°€**
```yaml
kafka:  
  bootstrap-servers: localhost:29092  
  consumer:  
    group-id: post-consumer-group  
    auto-offset-reset: earliest  
    key-deserializer: org.apache.kafka.common.serialization.StringDeserializer  
    value-deserializer: org.apache.kafka.common.serialization.StringDeserializer  
  producer:  
    key-serializer: org.apache.kafka.common.serialization.StringSerializer  
    value-serializer: org.apache.kafka.common.serialization.StringSerializer

data:  
  redis:  
    host: redis  
    port: 6379
```
### **3) Dockerë¡œ Kafka, Zookeeper, MySQL ì„¤ì •**
```bash
# Docker Compose íŒŒì¼ ì‘ì„± (docker-compose.yml)
services:  
  mysql:  
    image: mysql:8  
    container_name: mysql  
    restart: always  
    environment:  
      MYSQL_ROOT_PASSWORD: root  
      MYSQL_DATABASE: mydb  
      MYSQL_USER: user  
      MYSQL_PASSWORD: password  
    ports:  
      - "3306:3306"  
  redis:  
    image: "redis:latest"  
    container_name: redis  
    ports:  
      - "6379:6379"  
    restart: always  
  
  zookeeper:  
    image: quay.io/debezium/zookeeper:3.0  
    container_name: zookeeper  
    restart: always  
    ports:  
      - "2181:2181"  
  
  kafka:  
    image: confluentinc/cp-kafka:latest  
    container_name: kafka  
    restart: always  
    environment:  
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181  
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,PLAINTEXT_HOST://0.0.0.0:29092  
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092  
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT  
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT  
      KAFKA_BROKER_ID: 1  
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1  
    ports:  
      - "9092:9092"  
      - "29092:29092"  
    depends_on:  
      - zookeeper  
  
  debezium:  
    image: quay.io/debezium/connect:latest  
    container_name: debezium  
    restart: always  
    ports:  
      - "8083:8083"  
    environment:  
      BOOTSTRAP_SERVERS: kafka:9092  
      GROUP_ID: post-group  
      CONFIG_STORAGE_TOPIC: debezium_configs  
      OFFSET_STORAGE_TOPIC: debezium_offsets  
      STATUS_STORAGE_TOPIC: debezium_status  
    #      database.include.list: mydb  
    #      table.include.list: mydb.post    
    depends_on:  
      - kafka  
      - mysql
```
##### ğŸ“Œ docker ëª…ë ¹ì–´ ì°¸ê³ 
```bash
# ì»¨í…Œì´ë„ˆ ì‹¤í–‰
docker-compose up -d

# ì»¨í…Œì´ë„ˆ ì¤‘ì§€
docker-compose down

# íŠ¹ì • ì»¨í…Œì´ë„ˆë§Œ ì¬ì‹œì‘
docker-compose restart <container-name>

# ë„ì»¤ ì»¨í…Œì´ë„ˆ ìƒíƒœí™•ì¸
docker ps 
```
### **4) MySQL CDC ì„¤ì •**
```bash
 # mysql ì»¨í…Œì´ë„ˆì— ì ‘ì†
 docker exec -it mysql bash  
```
```sql
-- ì‚¬ìš©ì ìƒì„± ë° ê¶Œí•œ ë¶€ì—¬
CREATE USER 'debezium'@'%' IDENTIFIED BY 'dbz';
GRANT SELECT, RELOAD, SHOW DATABASES, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'debezium'@'%';
FLUSH PRIVILEGES;
```

>[!NOTE]
>Debezium MySQL ì»¤ë„¥í„° ì„¤ì • ì „ì— ì»¤ë„¥í„°ê°€ ë³€ê²½ì‚¬í•­ì„ ìº¡ì³í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì˜ê¶Œí•œì„ ë¶€ì—¬í•´ì•¼í•©ë‹ˆë‹¤.

### **5) Debezium MySQL ì»¤ë„¥í„° ì„¤ì •**
##### ğŸ“Œ ì»¤ë„¥í„° ë“±ë¡
- **Method**: `POST`
- **URL**: `http://localhost:8083/connectors/`
- **Content-Type**: `application/json`
##### ğŸ“ ìš”ì²­ ë³¸ë¬¸ (Request Body)
```json
{
Â  "name": "mydb-connector", //ì»¤ë„¥í„°ëª…
Â  "config": {
Â  Â  "connector.class": "io.debezium.connector.mysql.MySqlConnector",
Â  Â  "database.hostname": "mysql",
Â  Â  "database.port": "3306",
Â  Â  "database.user": "debezium", //ê¶Œí•œ ë¶€ì—¬ë°›ì€ ê³„ì •ìœ¼ë¡œ ë“±ë¡
Â  Â  "database.password": "dbz",
Â  Â  "database.server.id": "184054", // ê³ ìœ í•œ ì •ìˆ˜ ê°’ì´ì–´ì•¼ í•˜ë©°, ë‹¤ë¥¸ MySQL ì„œë²„                                          ë˜ëŠ” Debezium ì¸ìŠ¤í„´ìŠ¤ì™€ ì¤‘ë³µë˜ë©´ ì•ˆë¨
Â  Â  "topic.prefix": "mingle", //prefix ê°€ ì—†ìœ¼ë©´ ë“±ë¡ì´ì•ˆë˜ì—ˆìŒ
Â  Â  "database.include.list": "mydb", //cdc ëŒ€ìƒì€ mydb ì „ì²´
Â  Â  "schema.history.internal.kafka.bootstrap.servers": "kafka:9092", 
Â  Â  "schema.history.internal.kafka.topic": "schemahistory.mydb"
Â  }
}
```
##### ğŸ“ Response Body(ì •ìƒìƒíƒœ)
```json
{
  "name": "mydb-connector",
  "config": {
    "connector.class": "io.debezium.connector.mysql.MySqlConnector",
    "database.hostname": "mysql",
    "database.port": "3306",
    "database.user": "debezium",
    "database.password": "dbz",
    "database.server.id": "184054",
    "topic.prefix": "mingle",
    "database.include.list": "mydb",
    "schema.history.internal.kafka.bootstrap.servers": "kafka:9092",
    "schema.history.internal.kafka.topic": "schemahistory.mydb",
    "name": "mydb-connector"
  },
  "tasks": [],
  "type": "source"
}
```
##### ğŸ“Œ  ì»¤ë„¥í„° ë“±ë¡ í›„ í™•ì¸
- **Method**: `GET`
- **URL** : `http://localhost:8083/connectors`
##### ğŸ“ Response Body(ì •ìƒìƒíƒœ)
``` json
[
	"mydb-connector"
]
```
##### ğŸ“Œ  ì»¤ë„¥í„° ìƒíƒœ í™•ì¸
- **Method**: `GET`
- **URL**: `http://localhost:8083/connectors/<ì»¤ë„¥í„°ëª…>/status`
##### ğŸ“ Response Body(ì •ìƒ ìƒíƒœ)
```json
{
  "name": "mydb-connector",
  "connector": {
    "state": "RUNNING",
    "worker_id": "kafka-connect:8083"
  },
  "tasks": [
    {
      "id": 0,
      "state": "RUNNING",
      "worker_id": "kafka-connect:8083"
    }
  ],
  "type": "source"
}
```
##### ğŸ“Œ  ì»¤ë„¥í„° ì‚­ì œ
- Method: `DELETE`
- URL: `http://localhost:8083/connectors/<ì»¤ë„¥í„°ëª…>`
### **6) KafkaConsumer.java**
```java
@Slf4j  
@Service  
@RequiredArgsConstructor  
public class PostKafkaConsumer {  
  
    private final ObjectMapper objectMapper;  
    private final RedisService redisService;  
  
    private static final long FOLLOWER_ID = 100L; // í…ŒìŠ¤íŠ¸ìš©  
  
    @KafkaListener(topics = "mingle.mydb.post", groupId = "post-consumer-group")  
    public void listen(ConsumerRecord<String, String> record) {  
        try {  
            JsonNode payload = extractPayload(record.value());  
            if (payload == null) return;  
  
            String operation = payload.get("op").asText();  
            switch (operation) {  
                case "c" -> handleInsert(payload);  
                case "u" -> handleUpdate(payload);  
                case "d" -> handleDelete(payload);  
                default -> log.warn("ì•Œ ìˆ˜ ì—†ëŠ” ì´ë²¤íŠ¸ íƒ€ì…: {}", operation);  
            }  
  
        } catch (Exception e) {  
            log.error("Kafka ë©”ì‹œì§€ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {}", e.getMessage(), e);  
        }  
    }  
  
    private JsonNode extractPayload(String message) throws Exception {  
        JsonNode jsonNode = objectMapper.readTree(message);  
        return jsonNode.get("payload");  
    }  
  
    private void handleInsert(JsonNode payload) {  
        JsonNode afterNode = payload.get("after");  
        if (afterNode == null) return;  
  
        long id = afterNode.get("id").asLong();  
        long authorId = afterNode.get("author_id").asLong();  
        String content = afterNode.get("content").asText();  
        long createdAt = afterNode.get("created_at").asLong();  
  
        log.info("ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì¶”ê°€ë¨: ID={}, ì‘ì„±ì ID={}, ë‚´ìš©={}, ìƒì„±ì‹œê°„={}", id, authorId, content, createdAt);  
        redisService.updateCache(FOLLOWER_ID, id);  
    }  
  
    private void handleUpdate(JsonNode payload) {  
        JsonNode afterNode = payload.get("after");  
        if (afterNode == null) return;  
  
        long id = afterNode.get("id").asLong();  
        long authorId = afterNode.get("author_id").asLong();  
  
        log.info("ê²Œì‹œê¸€ ì—…ë°ì´íŠ¸: ID={}, ì‘ì„±ì ID={}, ë³€ê²½ëœ ë°ì´í„°={}", id, authorId, afterNode);  
        redisService.updateCache(FOLLOWER_ID, id);  
    }  
  
    private void handleDelete(JsonNode payload) {  
        JsonNode beforeNode = payload.get("before");  
        if (beforeNode == null) return;  
  
        long deletedId = beforeNode.get("id").asLong();  
        long authorId = beforeNode.get("author_id").asLong();  
  
        log.info("ê²Œì‹œê¸€ ì‚­ì œë¨: ID={}, ì‘ì„±ì ID={}", deletedId, authorId);  
        redisService.deleteCache(FOLLOWER_ID, deletedId);  
    }  
}
```
### **6) Redis Config**
```java
@Configuration  
public class RedisConfig {  
    @Bean  
    public RedisConnectionFactory redisConnectionFactory() {  
        return new LettuceConnectionFactory();  
    }  
  
    @Bean  
    public RedisTemplate<String, String> redisTemplate(RedisConnectionFactory connectionFactory) {  
        RedisTemplate<String, String> template = new RedisTemplate<>();  
        template.setConnectionFactory(connectionFactory);  
        template.setKeySerializer(new StringRedisSerializer());  
        template.setValueSerializer(new StringRedisSerializer());  
        return template;  
    }  
}
```
### **7) RedisService.java**
```java
@Service  
@RequiredArgsConstructor  
public class RedisService {  
  
    private final RedisTemplate<String, String> redisTemplate;  
  
    public void updateCache(Long followerId, Long postId) {  
        String key = "newsfeed:user:" + followerId;  
        // ìµœì‹  ê²Œì‹œê¸€ ì¶”ê°€  
        redisTemplate.opsForList().leftPush(key, postId.toString());  
        // ë‰´ìŠ¤í”¼ë“œ ìµœëŒ€ ê°œìˆ˜ ì œí•œ  
        redisTemplate.opsForList().trim(key, 0, 19);  
    }  
  
    public void deleteCache(Long followerId, Long postId) {  
        String key = "newsfeed:user:" + followerId;  
        // íŠ¹ì • postIdë§Œ ì œê±°  
        redisTemplate.opsForList().remove(key, 1, postId.toString());  
    }  
}
```
## **5. ê²°ê³¼ í™•ì¸**

##### **1) kafka ìƒì„±ëœ topics í™•ì¸**
```bash
docker exec -it kafka kafka-topics --bootstrap-server localhost:9092 --list
```
**âœ… í† í”½ ìƒì„± ì •ìƒì¼ ë•Œ ê²°ê³¼**
```bash
__consumer_offsets
debezium_configs
debezium_offsets
debezium_status
mingle
mingle.mydb.post
mingle.mydb.users
schemahistory.mydb
```
##### **2) MySQLì—ì„œ ë°ì´í„° ë³€ê²½ í…ŒìŠ¤íŠ¸**
```sql
insert into post (created_at, content, author_id) values (now(), 'content test','author');

update post set content='update test' where id = 12;

delete from post where id = 6;
```
##### **3) Kafka Consumerë¥¼ í†µí•´ ì´ë²¤íŠ¸ í™•ì¸**
```bash
 docker exec -it kafka bash -c 'kafka-console-consumer --bootstrap-server kafka:29092 --topic mingle.mydb.post --from-beginning'
```
>[!TIP]
>-- topic mingle.mydb.post
>â€¢ ì†Œë¹„í•  **Kafka í† í”½ ì´ë¦„** (mingle.mydb.post)

âœ… **ì •ìƒì ì¸ ê²½ìš° ì¶œë ¥ ì˜ˆì‹œ**
```json
{
  "payload": {
    "op": "c",
    "after": {
      "id": 15,
      "content": "content test",
      "created_at": "2025-03-02T12:34:56Z"
    }
  }
}
```
```json
{
  "payload": {
    "op": "u",
    "after": {
      "id": 12,
      "content": "update test",
      "created_at": "2025-03-02T12:30:00Z"
    }
  }
}
```
##### **4) Java Kafka Consumer ë¡œê·¸ í™•ì¸**
```bash
ìƒˆë¡œìš´ ê²Œì‹œê¸€ ì¶”ê°€ë¨: ID=15, ë‚´ìš©=content test, ìƒì„±ì‹œê°„=2025-03-02T12:34:56Z
ê²Œì‹œê¸€ ì—…ë°ì´íŠ¸: {"id": 12, "content": "update test", "created_at": "2025-03-02T12:30:00Z"}
```
##### **5) Redis ì €ì¥ í™•ì¸**
```bash
# redis cli ì ‘ì†
docker exec -it redis redis-cli
# í‚¤ í™•ì¸
keys *
# ê°’ í™•ì¸
rlange newsfeed:user:100
```

## **6. ê²°ë¡ **
 Kafka, Debezium, MySQL, Redisë¥¼ í™œìš©í•˜ì—¬ **CDC ê¸°ë°˜ì˜ ì‹¤ì‹œê°„ ë°ì´í„° ë™ê¸°í™” ì‹œìŠ¤í…œ**ì„ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ë‹¤ë£¨ì—ˆìŠµë‹ˆë‹¤.

âœ… **CDC êµ¬í˜„ì´ ì„±ê³µì ìœ¼ë¡œ ì´ë£¨ì–´ì¡Œë‹¤ë©´ ë‹¤ìŒê³¼ ê°™ì€ ë™ì‘ì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.**
1. **MySQL ë°ì´í„° ë³€ê²½ â†’ Kafka í† í”½ìœ¼ë¡œ ì´ë²¤íŠ¸ ìƒì„±**
2. **Kafka Consumerê°€ ë³€ê²½ ì‚¬í•­ì„ ê°ì§€í•˜ì—¬ ë¡œê·¸ ì¶œë ¥**
3. **Kafka ë©”ì‹œì§€ê°€ Redisì— ìºì‹œë¡œ ì €ì¥ë¨**

ì´ì œ CDCë¥¼ í™œìš©í•˜ì—¬ ì‹¤ì‹œê°„ ë°ì´í„° ë°˜ì˜ì´ í•„ìš”í•œ ë‹¤ì–‘í•œ ì„œë¹„ìŠ¤(ì˜ˆ: í”¼ë“œ, ì•Œë¦¼ ì‹œìŠ¤í…œ)ì— ì ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.